{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453b1bd7-a0c2-449c-9719-50e8f5de06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from diffusers import UNet2DConditionModel\n",
    "import torch\n",
    "from src.models.evolve_prior_model import PriorModelEvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43103544-9a7a-4e4a-b21c-8fdd4f1646ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829e5c77-3fd4-417b-810c-5a4ea9bfe805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch stable-diffusion-v1-5/stable-diffusion-inpainting: stable-diffusion-v1-5/stable-diffusion-inpainting does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "DS_unet = UNet2DConditionModel.from_pretrained(\n",
    "    'Lykon/dreamshaper-8',\n",
    "    subfolder='unet',\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "SD_inpaint_unet = UNet2DConditionModel.from_pretrained(\n",
    "    'stable-diffusion-v1-5/stable-diffusion-inpainting',\n",
    "    subfolder='unet',\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "SD_unet = UNet2DConditionModel.from_pretrained(\n",
    "    'stable-diffusion-v1-5/stable-diffusion-v1-5',\n",
    "    subfolder='unet',\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3681b4a7-3815-4fab-a4b5-0655596fe654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "beta = 1.1\n",
    "\n",
    "# alpha * (W_inp - W_base)\n",
    "for (name, param1), (_, param2) in zip(SD_inpaint_unet.named_parameters(), SD_unet.named_parameters()):\n",
    "    if 'conv_in' in name:\n",
    "        with torch.no_grad():\n",
    "            if len(param1.data.shape) == 4:\n",
    "                # conv weights\n",
    "                param1.data[:, :4, :, :].sub_(param2) * alpha\n",
    "                param1.data[:, 4:, :, :] * alpha\n",
    "            else:\n",
    "                # conv bias\n",
    "                param1.data.sub_(param2) * alpha\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            param1.data.sub_(param2) * alpha\n",
    "\n",
    "# beta * (W_DS - W_base)\n",
    "for (name, param1), (_, param2) in zip(DS_unet.named_parameters(), SD_unet.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        param1.data.sub_(param2) * beta\n",
    "\n",
    "# W_base + alpha * (W_inp - W_base) + beta * (W_DS - W_base)\n",
    "# Here, we treat W_inp as W_base in the above expression to implement easier.\n",
    "for (name, param1), (_, param2), (_, param3) in zip(SD_inpaint_unet.named_parameters(), SD_unet.named_parameters(), DS_unet.named_parameters()):\n",
    "    if 'conv_in' in name:\n",
    "        if len(param1.data.shape) == 4:\n",
    "            param1.data[:, :4, :, :].add_(param2)\n",
    "            param1.data[:, :4, :, :].add_(param3)\n",
    "        else:\n",
    "            param1.data.add_(param2)\n",
    "            param1.data.add_(param3)\n",
    "    else:\n",
    "        param1.data.add_(param2)\n",
    "        param1.data.add_(param3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a232af3b-2316-4555-b22b-1cd7d539deec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1215, -0.2026,  0.1359,  0.0339,  0.0492, -0.0740, -0.0136,  0.0609,\n",
       "        -0.0308,  0.0450, -0.0215, -0.0568,  0.1191,  0.0833, -0.0334, -0.1379,\n",
       "        -0.1210,  0.0368,  0.0194,  0.0812, -0.1058,  0.0873, -0.0411,  0.0468,\n",
       "         0.0703,  0.0294,  0.1013, -0.1018, -0.0536,  0.0298, -0.0308,  0.0386,\n",
       "         0.0598, -0.0557,  0.0455,  0.0764, -0.1082,  0.0995,  0.0306,  0.0428,\n",
       "         0.0332, -0.0571, -0.1096, -0.0758,  0.0496, -0.0625,  0.0792,  0.0332,\n",
       "        -0.1465, -0.0933, -0.1064, -0.1371,  0.0522,  0.0326, -0.1034,  0.1141,\n",
       "         0.0147,  0.0958,  0.0993, -0.1476,  0.1267, -0.0881, -0.1114, -0.1041,\n",
       "         0.0145, -0.0811,  0.1450, -0.0221, -0.0632,  0.1099,  0.0255,  0.1118,\n",
       "        -0.0884, -0.0123, -0.0899,  0.0185,  0.1083,  0.1432, -0.0765,  0.1047,\n",
       "         0.0667, -0.1564,  0.0427, -0.1071, -0.1011,  0.1199,  0.0596,  0.1506,\n",
       "        -0.1110, -0.1161,  0.1810,  0.1586,  0.1204, -0.1119, -0.1589, -0.0591,\n",
       "        -0.1099, -0.0024,  0.1182, -0.0673,  0.0012,  0.0879, -0.0958,  0.1598,\n",
       "        -0.1137,  0.0861,  0.0443,  0.0784, -0.1409,  0.0409, -0.0262,  0.0578,\n",
       "        -0.0919, -0.0154, -0.0600, -0.1292,  0.1136,  0.1227,  0.0277, -0.1014,\n",
       "         0.0605, -0.0473, -0.0753, -0.0545, -0.0274, -0.0338,  0.0994,  0.0831,\n",
       "        -0.0420, -0.1102,  0.0811,  0.0622, -0.0717,  0.0698, -0.1056, -0.0361,\n",
       "         0.0898,  0.0768,  0.0306, -0.0803, -0.0233, -0.0767,  0.0990, -0.0625,\n",
       "        -0.1427, -0.0064, -0.1227,  0.1616,  0.0640,  0.2246,  0.0005,  0.1311,\n",
       "         0.0647,  0.0169, -0.1245, -0.0260,  0.0077, -0.0439,  0.0063, -0.0755,\n",
       "         0.0874, -0.0562,  0.0804, -0.0113,  0.0033,  0.0738, -0.0794, -0.0400,\n",
       "        -0.0262,  0.0229,  0.0606, -0.0242,  0.0920,  0.0502,  0.0770, -0.0872,\n",
       "         0.0019, -0.1133,  0.0359, -0.0500,  0.0981,  0.0209,  0.1279,  0.0333,\n",
       "         0.0029,  0.0392, -0.1164, -0.0903,  0.0760, -0.0673, -0.1709,  0.1436,\n",
       "         0.1686, -0.1313, -0.0555, -0.1279,  0.0149,  0.1037,  0.1421, -0.1285,\n",
       "         0.0589,  0.0620, -0.1367,  0.0497,  0.1006, -0.0859, -0.1186,  0.1223,\n",
       "        -0.1630, -0.0714,  0.0367, -0.1133,  0.0322, -0.0325,  0.0426,  0.0021,\n",
       "        -0.0464,  0.0955,  0.1089, -0.1009,  0.1365, -0.0137,  0.0670, -0.0344,\n",
       "         0.1234, -0.1348, -0.0251, -0.0406, -0.0004, -0.0848,  0.0441, -0.0453,\n",
       "        -0.0331, -0.1219,  0.0204, -0.0595, -0.0830, -0.0125,  0.0260,  0.1427,\n",
       "        -0.1105, -0.0197, -0.0257,  0.1370,  0.0823,  0.0723,  0.1121,  0.0797,\n",
       "        -0.0561, -0.1202, -0.0928,  0.0399,  0.1477, -0.0499,  0.0613,  0.1037,\n",
       "         0.0533,  0.1025, -0.0848, -0.1353, -0.0137,  0.0933,  0.0495, -0.1005,\n",
       "         0.0591,  0.0265,  0.1343, -0.1033, -0.0752,  0.0068, -0.0657,  0.0656,\n",
       "         0.0261, -0.0626, -0.0845,  0.0831, -0.0909, -0.0235,  0.1157,  0.1004,\n",
       "        -0.0015,  0.1100,  0.0925, -0.0992, -0.0282, -0.0508,  0.0696, -0.0836,\n",
       "         0.0149, -0.0148, -0.1294,  0.0117, -0.0268, -0.1313,  0.0594,  0.0714,\n",
       "        -0.1150,  0.0576, -0.0136,  0.0431,  0.0928, -0.0668, -0.1357,  0.0625,\n",
       "        -0.0320, -0.0809,  0.0807, -0.0055,  0.0632,  0.0475,  0.0239, -0.0185,\n",
       "        -0.1375, -0.0788,  0.0036,  0.0186,  0.1080, -0.0326, -0.0100, -0.0892],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SD_inpaint_unet.conv_in.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6738f1af-6e1a-48c9-a616-c9ea28e56c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_unet = copy.deepcopy(SD_inpaint_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62341e-7c32-4c3f-94d1-e4af269f9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_prior_model(base, inpaint, shaper):\n",
    "    \"\"\" Prior Model Evolution\n",
    "    (section 3.3 in https://arxiv.org/abs/2405.18172)\n",
    "    \n",
    "    This implementation use in-place PyTorch operation for tensors.\n",
    "    \"\"\"\n",
    "    # default values from paper\n",
    "    alpha = 1.0\n",
    "    beta = 1.1\n",
    "\n",
    "    # alpha * (W_inp - W_base)\n",
    "    for (name, param1), (_, param2) in zip(inpaint.named_parameters(), base.named_parameters()):\n",
    "        if 'conv_in' in name:\n",
    "            with torch.no_grad():\n",
    "                if len(param1.data.shape) == 4:\n",
    "                    # conv weights\n",
    "                    param1.data[:, :4, :, :].sub_(param2) * alpha\n",
    "                    param1.data[:, 4:, :, :] * alpha\n",
    "                else:\n",
    "                    # conv bias\n",
    "                    param1.data.sub_(param2) * alpha\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                param1.data.sub_(param2) * alpha\n",
    "\n",
    "    # beta * (W_DS - W_base)\n",
    "    for (name, param1), (_, param2) in zip(shaper.named_parameters(), base.named_parameters()):\n",
    "        with torch.no_grad():\n",
    "            param1.data.sub_(param2) * beta\n",
    "    \n",
    "    # W_base + alpha * (W_inp - W_base) + beta * (W_DS - W_base)\n",
    "    # Here, we treat W_inp as W_base in the above expression to implement easier.\n",
    "    for (name, param1), (_, param2), (_, param3) in zip(inpaint.named_parameters(), base.named_parameters(), shaper.named_parameters()):\n",
    "        if 'conv_in' in name:\n",
    "            if len(param1.data.shape) == 4:\n",
    "                param1.data[:, :4, :, :].add_(param2)\n",
    "                param1.data[:, :4, :, :].add_(param3)\n",
    "            else:\n",
    "                param1.data.add_(param2)\n",
    "                param1.data.add_(param3)\n",
    "        else:\n",
    "            param1.data.add_(param2)\n",
    "            param1.data.add_(param3)\n",
    "    \n",
    "    return copy.deepcopy(inpaint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead00dc-ea6d-48c9-9461-faeec99574db",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d63b43-eec0-4206-a5f8-ea6b3676d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evolver = PriorModelEvolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab61e73-142b-4e1a-b9ad-40d458cd4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch stable-diffusion-v1-5/stable-diffusion-inpainting: stable-diffusion-v1-5/stable-diffusion-inpainting does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "my_unet = UNet2DConditionModel.from_pretrained(\n",
    "    'stable-diffusion-v1-5/stable-diffusion-inpainting',\n",
    "    subfolder='unet',\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52fd52f-f8e0-47d7-a70f-024869f06ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2DConditionModel(\n",
       "  (conv_in): Conv2d(9, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2DCrossAttn(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Transformer2DModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evolver(my_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffefd46-103a-486f-876a-d3fbb1f41b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_evolver\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
