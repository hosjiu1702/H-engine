{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00cecd66-87d6-405e-8c1f-8ed1af38de7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.autoencoder_kl import AutoencoderKL\n",
    "from src.models.emasc import EMASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc980865-d730-44bb-bae3-9bac2810ecf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_channels_list = [128, 128, 128, 256, 512]\n",
    "output_channels_list = [128, 256, 512, 512, 512]\n",
    "emasc = EMASC(input_channels_list, output_channels_list).to('cuda', dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3db210-53cf-4bae-9abb-9962222f999f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\n",
    "    'stable-diffusion-v1-5/stable-diffusion-inpainting',\n",
    "    subfolder='vae',\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=False\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b33831-de96-4d57-9b74-feeda28fb548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs, c, h, w = 16, 3, 512, 384\n",
    "x = torch.randn(bs, c, h, w).to('cuda', dtype=torch.float16) # move the input to device & cast it to float16 data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c502060c-ee17-467e-8cee-e465d9edab3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 64, 48])\n",
      "\n",
      "Intermediate features at each of Downblock Encoder of VAE:\n",
      "([batch size, channel, height, weight])\n",
      "  torch.Size([16, 128, 512, 384])\n",
      "  torch.Size([16, 128, 512, 384])\n",
      "  torch.Size([16, 128, 256, 192])\n",
      "  torch.Size([16, 256, 128, 96])\n",
      "  torch.Size([16, 512, 64, 48])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # with torch.amp.autocast('cuda'):\n",
    "    posterior, intermediate_features = vae.encode(x)\n",
    "    print(posterior.latent_dist.sample().shape)\n",
    "    print('')\n",
    "    print('Intermediate features at each of Downblock Encoder of VAE:')\n",
    "    print(f'([batch size, channel, height, weight])')\n",
    "    for in_feats in intermediate_features:\n",
    "        print(f'  {in_feats.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b012ec1-381b-4094-88b8-e8b1ac35ee89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 512, 384])\n",
      "torch.Size([16, 256, 512, 384])\n",
      "torch.Size([16, 512, 256, 192])\n",
      "torch.Size([16, 512, 128, 96])\n",
      "torch.Size([16, 512, 64, 48])\n"
     ]
    }
   ],
   "source": [
    "# Emasc outputs\n",
    "emasc_outputs = emasc(intermediate_features)\n",
    "for i in range(len(emasc_outputs)):\n",
    "    print(emasc_outputs[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e21a14-3783-4c70-bb16-f6498aa925ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 64, 48])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents = posterior.latent_dist.sample()\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8213438e-30b7-425a-a26c-b407ddd89c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512, 64, 48])\ttorch.Size([16, 512, 64, 48])\n",
      "torch.Size([16, 512, 128, 96])\ttorch.Size([16, 512, 128, 96])\n",
      "torch.Size([16, 512, 256, 192])\ttorch.Size([16, 512, 256, 192])\n",
      "torch.Size([16, 256, 512, 384])\ttorch.Size([16, 256, 512, 384])\n",
      "torch.Size([16, 128, 512, 384])\ttorch.Size([16, 128, 512, 384])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    vae.decode(z=latents, intermediate_features=emasc_outputs)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": ".venv-test",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "venv38-new",
   "language": "python",
   "name": ".venv-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
