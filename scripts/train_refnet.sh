export TORCH_DISTRIBUTED_DEBUG=INFO
export MIXED_PRECISION_TRAINING='bf16'
export NUM_GPUS=8
export NUM_NODES=1
export MAIN_PROCESS_PORT=29506
export HUGGINGFACE_MODEL_ID=stable-diffusion-v1-5/stable-diffusion-inpainting
export REFERENCE_NET=stable-diffusion-v1-5/stable-diffusion-v1-5
export REFERENCE_ENCODER_MODEL_ID=patrickjohncyh/fashion-clip
export VAE_MODEL=stabilityai/sd-vae-ft-mse
export VITONHD_DATAPATH=datasets/vitonhd
export DRESSCODE_DATAPATH=datasets/dresscode
export OUTPUT_DIR=results/refnet_2503_dc
export PROJECT_NAME='TEST-VTO'
export WANDB_NAME_RUN='fusion_block=full__self_attn=midup'
export CFG=1.5
export SNR_GAMMA=5
export WIDTH=384
export HEIGHT=512
export TRAIN_BATCH_SIZE=8
export TEST_BATCH_SIZE=8
export SEED=2114
export ENABLE_TRACKER=true

CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u -m accelerate.commands.launch --main_process_port=$MAIN_PROCESS_PORT --mixed_precision=$MIXED_PRECISION_TRAINING --num_processes=$NUM_GPUS --num_machines=$NUM_NODES --dynamo_backend='no' \
train_refnet.py \
--pretrained_model_name_or_path=$HUGGINGFACE_MODEL_ID \
--refnet_model=$REFERENCE_NET \
--image_encoder_path=$REFERENCE_ENCODER_MODEL_ID \
--vae_path=$VAE_MODEL \
--merge_hd_dc \
--use_subset \
--num_subset_samples=500 \
--data_dir=$DRESSCODE_DATAPATH \
--vitonhd_datapath=$VITONHD_DATAPATH \
--dresscode_datapath=$DRESSCODE_DATAPATH \
--cfg=$CFG \
--width=$WIDTH \
--height=$HEIGHT \
--seed=$SEED \
--snr_gamma=$SNR_GAMMA \
--use_dilated_mask \
--use_densepose \
--allow_tf32 \
--train_midup_self_attn \
--enable_mlp \
--train_mlp \
--train_with_8bit \
--output_dir=$OUTPUT_DIR \
--train_batch_size=$TRAIN_BATCH_SIZE \
--test_batch_size=$TEST_BATCH_SIZE \
--gradient_accumulation_steps=1 \
--mixed_precision=$MIXED_PRECISION_TRAINING \
--num_workers=32 \
--num_train_epochs=1000 \
--max_train_steps=300000 \
--checkpointing_steps=30000 \
--eval_steps=100000000 \
--validation_steps=500 \
--lr=1e-5 \
--use_tracker=$ENABLE_TRACKER \
--project_name=$PROJECT_NAME \
--wandb_name_run=$WANDB_NAME_RUN